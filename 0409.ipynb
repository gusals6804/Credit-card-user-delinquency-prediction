{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "exciting-russell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "display(HTML(\"<style>.container { width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "atlantic-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./open/train.csv')\n",
    "train = train.drop(['index'], axis=1)\n",
    "train.fillna('NAN', inplace=True) \n",
    "\n",
    "\n",
    "test = pd.read_csv('./open/test.csv')\n",
    "test = test.drop(['index'], axis=1)\n",
    "test.fillna('NAN', inplace=True)\n",
    "\n",
    "submit = pd.read_csv('./open/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "extra-morocco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36457, 19)"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.concat([train, test], axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "illegal-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(['FLAG_MOBIL'], axis=1)\n",
    "test=test.drop(['FLAG_MOBIL'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "million-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_col = []\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == 'object':\n",
    "        object_col.append(col)\n",
    "#     elif col in ['phone',  'email', 'work_phone', 'FLAG_MOBIL']:\n",
    "#         object_col.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "surrounded-object",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(train.loc[:,object_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "social-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "train.drop(object_col, axis=1, inplace=True)\n",
    "train = pd.concat([train, train_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "theoretical-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_onehot_df = pd.DataFrame(enc.transform(test.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "test.drop(object_col, axis=1, inplace=True)\n",
    "test = pd.concat([test, test_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "helpful-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(df):\n",
    "    df = np.array(df).reshape(-1, 1)\n",
    "    result = MinMaxScaler().fit_transform(df)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "personal-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_to_age(x):\n",
    "    return (x*-1)/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "personal-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마이너스 값 변환\n",
    "def minus(x):\n",
    "    return x * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "eastern-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['income_total'] = train['income_total']/10000\n",
    "train['income_total_dev'] = (train['income_total'] - train['income_total'].mean())**2\n",
    "train['income_total_log'] = train['income_total'].apply(np.log)\n",
    "#train['income_total_minmax'] = train['income_total'].apply(minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "portuguese-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['career'] = train['DAYS_EMPLOYED'].apply( lambda x : 1 if x < 0 else 0)\n",
    "train['DAYS_EMPLOYED_log'] = train['DAYS_EMPLOYED'].map(lambda x: x if x < 0 else 0).apply(lambda x: np.log1p(x*-1))\n",
    "train.loc[train['DAYS_EMPLOYED'] >= 0,'DAYS_EMPLOYED']=0\n",
    "train['DAYS_EMPLOYED'] = train['DAYS_EMPLOYED'].apply(days_to_age)\n",
    "# train['DAYS_EMPLOYED_one'] = train['DAYS_EMPLOYED']\n",
    "# train.loc[train['DAYS_EMPLOYED_one'] > 0,'DAYS_EMPLOYED']=0\n",
    "#train['DAYS_EMPLOYED_dev'] = (train['DAYS_EMPLOYED'] - train['DAYS_EMPLOYED'].mean())**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "gothic-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['begin_month'] = train['begin_month'].apply(minus)\n",
    "#train['begin_month'] = train['begin_month']//12\n",
    "# train.loc[train['begin_month'] < 0,'begin_month']=0\n",
    "# train.loc[train['begin_month'] > 0,'begin_month']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "individual-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DAYS_BIRTH'] = train['DAYS_BIRTH'].apply(days_to_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "mathematical-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['diff_child'] = train['family_size'] - train['child_num']\n",
    "train.loc[train['diff_child'] < 0,'diff_child']=0\n",
    "train.loc[train['diff_child'] > 0,'diff_child']=1\n",
    "train.loc[train['child_num'] >= 2,'child_num'] = 2\n",
    "train.loc[train['family_size'] >= 5,'child_num'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "synthetic-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['total_phone'] = train['work_phone'] + train['phone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "behavioral-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['income_total'] = test['income_total']/10000\n",
    "test['income_total_dev'] = (test['income_total'] - test['income_total'].mean())**2\n",
    "test['income_total_log'] = test['income_total'].apply(np.log)\n",
    "#test['income_total_minmax'] = test['income_total'].apply(minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "short-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['career'] = test['DAYS_EMPLOYED'].apply( lambda x : 1 if x < 0 else 0)\n",
    "test['DAYS_EMPLOYED_log'] = test['DAYS_EMPLOYED'].map(lambda x: x if x < 0 else 0).apply(lambda x: np.log1p(x*-1))\n",
    "test.loc[test['DAYS_EMPLOYED'] >= 0,'DAYS_EMPLOYED']=0\n",
    "test['DAYS_EMPLOYED'] = test['DAYS_EMPLOYED'].apply(days_to_age)\n",
    "# test['DAYS_EMPLOYED_one'] = test['DAYS_EMPLOYED']\n",
    "# test.loc[test['DAYS_EMPLOYED_one'] > 0,'DAYS_EMPLOYED']=0\n",
    "# test.loc[test['DAYS_EMPLOYED_one'] < 0,'DAYS_EMPLOYED']=1\n",
    "#test.loc[test['DAYS_EMPLOYED'] >= 0,'DAYS_EMPLOYED']=0\n",
    "#test['DAYS_EMPLOYED_dev'] = (test['DAYS_EMPLOYED'] - test['DAYS_EMPLOYED'].mean())**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "banned-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['DAYS_BIRTH'] = test['DAYS_BIRTH'].apply(days_to_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "waiting-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['diff_child'] = test['family_size'] - test['child_num']\n",
    "test.loc[test['diff_child'] < 0,'diff_child']=0\n",
    "test.loc[test['diff_child'] > 0,'diff_child']=1\n",
    "test.loc[test['child_num'] >= 2,'child_num'] = 2\n",
    "test.loc[test['family_size'] >= 5,'child_num'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "large-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['begin_month'] = test['begin_month'].apply(minus)\n",
    "#test['begin_month'] = test['begin_month']//12\n",
    "# test.loc[train['begin_month'] < 0,'begin_month']=0\n",
    "# test.loc[train['begin_month'] > 0,'begin_month']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "upset-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['total_phone'] = test['work_phone'] + test['phone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "assigned-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minus 변경하고\n",
    "#구간화 함수\n",
    "def make_bin(df, variable, n):\n",
    "    data = df\n",
    "    #data[variable] =- data[variable]\n",
    "    count, bin_dividers = np.histogram(data[variable], bins=n)\n",
    "    bin_names=[str(i) for i in range(n)]\n",
    "    data['%s_bin' % variable]=pd.cut(x=data[variable], bins=bin_dividers, labels=bin_names, include_lowest=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "endangered-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_bin(train, 'income_total', n=7)\n",
    "make_bin(train, 'income_total_log', n=25)\n",
    "make_bin(train, 'DAYS_BIRTH', n=10)\n",
    "# #make_bin(train, 'begin_month', n=6)\n",
    "make_bin(train, 'DAYS_EMPLOYED_log', n=20)\n",
    "#make_bin(train, 'DAYS_EMPLOYED', n=2)\n",
    "#make_bin(train, 'child_num', n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "thousand-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_bin(test, 'income_total', n=7)\n",
    "make_bin(test, 'income_total_log', n=25)\n",
    "make_bin(test, 'DAYS_BIRTH', n=10)\n",
    "# #make_bin(test, 'begin_month', n=6)\n",
    "make_bin(test, 'DAYS_EMPLOYED_log', n=20)\n",
    "#make_bin(train, 'DAYS_EMPLOYED', n=2)\n",
    "#make_bin(train, 'child_num', n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "restricted-detroit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "object_col = ['income_total_log_bin', 'DAYS_BIRTH_bin',  'DAYS_EMPLOYED_log_bin']\n",
    "enc.fit(train.loc[:,object_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "chemical-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "train.drop(object_col, axis=1, inplace=True)\n",
    "train = pd.concat([train, train_onehot_df], axis=1)\n",
    "train = train.drop(['income_total'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "upset-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_onehot_df = pd.DataFrame(enc.transform(test.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "test.drop(object_col, axis=1, inplace=True)\n",
    "test = pd.concat([test, test_onehot_df], axis=1)\n",
    "test = test.drop(['income_total'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "utility-sierra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26457, 109), (10000, 108))"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "interesting-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "import catboost as cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "comprehensive-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(train.drop(['credit'],axis=1), train['credit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "shared-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(max_depth, subsample, colsample_bytree, learning_rate):\n",
    "    params = {'eval_metric': 'mlogloss',\n",
    "                'objective': 'multi:softprob',\n",
    "                'gpu_id': 0,\n",
    "                'tree_method': 'gpu_hist',\n",
    "                'predictor': 'gpu_predictor',\n",
    "                #                 'booster' : 'dart',\n",
    "                'num_class' : 3,\n",
    "                'max_depth': int(max_depth),\n",
    "                'subsample': subsample,\n",
    "                'eta': learning_rate,\n",
    "                'colsample_bytree': colsample_bytree,   \n",
    "                #                 'rate_drop': rate_drop,\n",
    "                #               'max_delta_step':max_delta_step\n",
    "             }\n",
    "    # Used around 1000 boosting rounds in the full model\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round=200, nfold=5, early_stopping_rounds=50)    \n",
    "    # Bayesian optimization only knows how to maximize, not minimize, so return the negative RMSE\n",
    "    return -1.0 * cv_result['test-mlogloss-mean'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "associate-formula",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | subsample |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.7692  \u001b[0m | \u001b[0m 0.4027  \u001b[0m | \u001b[0m 0.1534  \u001b[0m | \u001b[0m 4.077   \u001b[0m | \u001b[0m 0.689   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.75    \u001b[0m | \u001b[95m 0.5543  \u001b[0m | \u001b[95m 0.1028  \u001b[0m | \u001b[95m 6.942   \u001b[0m | \u001b[95m 0.4016  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-0.7367  \u001b[0m | \u001b[95m 0.8786  \u001b[0m | \u001b[95m 0.1856  \u001b[0m | \u001b[95m 7.435   \u001b[0m | \u001b[95m 0.8552  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.7399  \u001b[0m | \u001b[0m 0.8083  \u001b[0m | \u001b[0m 0.02837 \u001b[0m | \u001b[0m 10.22   \u001b[0m | \u001b[0m 0.6205  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.7378  \u001b[0m | \u001b[0m 0.4955  \u001b[0m | \u001b[0m 0.08542 \u001b[0m | \u001b[0m 7.395   \u001b[0m | \u001b[0m 0.5738  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.7286  \u001b[0m | \u001b[95m 0.5128  \u001b[0m | \u001b[95m 0.07296 \u001b[0m | \u001b[95m 8.259   \u001b[0m | \u001b[95m 0.8375  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.7167  \u001b[0m | \u001b[95m 0.4376  \u001b[0m | \u001b[95m 0.05131 \u001b[0m | \u001b[95m 12.0    \u001b[0m | \u001b[95m 0.9687  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.7493  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 12.0    \u001b[0m | \u001b[0m 0.4     \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.7645  \u001b[0m | \u001b[0m 0.9428  \u001b[0m | \u001b[0m 0.01625 \u001b[0m | \u001b[0m 10.87   \u001b[0m | \u001b[0m 0.9671  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.7252  \u001b[0m | \u001b[0m 0.534   \u001b[0m | \u001b[0m 0.1676  \u001b[0m | \u001b[0m 9.58    \u001b[0m | \u001b[0m 0.9508  \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "xgb_bo = BayesianOptimization(xgb_evaluate, {\n",
    "                                'max_depth': (4, 12),\n",
    "                                'subsample': (0.4, 1.0),\n",
    "                                'colsample_bytree' :(0.4, 1.0),\n",
    "#                                 'rate_drop': (0.1, 0.5),\n",
    "                                'learning_rate': (0.01,0.2)})\n",
    "# Use the expected improvement acquisition function to handle negative numbers\n",
    "# Optimally needs quite a few more initiation points and number of iterations\n",
    "xgb_bo.maximize(init_points=5, n_iter = 5, acq='ei', xi=0.01, random_state=409)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "ranking-fraud",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.437585287361525,\n",
       " 'learning_rate': 0.051310789411336766,\n",
       " 'max_depth': 11.99880897321103,\n",
       " 'subsample': 0.9687212370190348}"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = xgb_bo.max['params']\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "hindu-southeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.3,\n",
       " 'learning_rate': 0.04,\n",
       " 'max_depth': 12,\n",
       " 'subsample': 0.8,\n",
       " 'eval_metric': 'mlogloss',\n",
       " 'objective': 'multi:softprob',\n",
       " 'num_class': 3,\n",
       " 'min_child_weight': 1.1,\n",
       " 'alpha': 0,\n",
       " 'gamma': 0}"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['max_depth'] = 12\n",
    "params['eval_metric'] = 'mlogloss'\n",
    "params['objective'] = 'multi:softprob'\n",
    "params['num_class'] = 3\n",
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 0.3\n",
    "params['min_child_weight'] = 1.1\n",
    "params['learning_rate'] = 0.04\n",
    "params['alpha'] = 0\n",
    "params['gamma'] = 0\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.cv(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=1000,\n",
    "    nfold=5,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval = 50\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "chemical-junction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0 : logloss:0.7026823425689432\n",
      "FOLD 1 : logloss:0.6923813601485534\n",
      "FOLD 2 : logloss:0.6837733398773795\n",
      "FOLD 3 : logloss:0.7029009338599247\n",
      "FOLD 4 : logloss:0.7143285191879775\n",
      "FOLD 5 : logloss:0.67391279505394\n",
      "FOLD 6 : logloss:0.6757419324773544\n",
      "FOLD 7 : logloss:0.6850064412354437\n",
      "FOLD 8 : logloss:0.704275892658726\n",
      "FOLD 9 : logloss:0.6834853166356922\n",
      "Mean:0.6918488873703935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_x = train.drop(['credit'],axis=1)\n",
    "train_y = train['credit']\n",
    "dtest2 = xgb.DMatrix(test)\n",
    "\n",
    "def run_kfold():\n",
    "    folds=StratifiedKFold(n_splits=10, shuffle=True, random_state=55)\n",
    "    outcomes=[]\n",
    "    sub=np.zeros((test.shape[0], 3))  \n",
    "    for n_fold, (train_index, val_index) in enumerate(folds.split(train_x, train_y)):\n",
    "        X_train, X_val = train_x.iloc[train_index], train_x.iloc[val_index]\n",
    "        y_train, y_val = train_y.iloc[train_index], train_y.iloc[val_index]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train, y_train)\n",
    "        dtest = xgb.DMatrix(X_val)\n",
    "#         clf.fit(X_train, y_train)\n",
    "        \n",
    "#         predictions=clf.predict_proba(X_val)\n",
    "        \n",
    "        final_gb = xgb.train(params, dtrain, num_boost_round=350, verbose_eval=50)\n",
    "\n",
    "        predictions = final_gb.predict(dtest)\n",
    "        test_predictions = final_gb.predict(dtest2)\n",
    "        \n",
    "        logloss=log_loss(to_categorical(y_val), predictions)\n",
    "        outcomes.append(logloss)\n",
    "        print(f\"FOLD {n_fold} : logloss:{logloss}\")\n",
    "        \n",
    "        sub+= test_predictions\n",
    "        \n",
    "        \n",
    "    mean_outcome=np.mean(outcomes)\n",
    "    \n",
    "    print(\"Mean:{}\".format(mean_outcome))\n",
    "    return sub/folds.n_splits\n",
    "\n",
    "my_submission = run_kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "modular-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "adaptive-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = xgb.XGBClassifier(colsample_bytree = 0.4, subsample=0.98, learning_rate=0.09, \n",
    "                         objective='multi:softprob', max_depth=10)\n",
    "clf2 = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "induced-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(estimators=[('rf', clf1), ('lgbm', clf2)], #모델 합치기\n",
    "    final_estimator=LogisticRegression(),\n",
    "                        n_jobs = -1, \n",
    "                        stack_method = 'predict_proba',\n",
    "                        cv = 5)\n",
    "# rf랑 lgb로부터 나온 예측값에 가중치를 주어서 새로운 파이널 모델에 넣고 재학습. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "endless-mother",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0 : logloss:0.7365110742085077\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-67a36b5d74b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mmy_submission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_kfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-55-67a36b5d74b7>\u001b[0m in \u001b[0;36mrun_kfold\u001b[1;34m(clf)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#         dtrain = xgb.DMatrix(X_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#         dtest = xgb.DMatrix(X_val)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'final_estimator_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    146\u001b[0m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0;32m    147\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_fit_single_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_estimators\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mest\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'drop'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m         )\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep2\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep2\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep2\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep2\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "def run_kfold(clf):\n",
    "    folds=StratifiedKFold(n_splits=5, shuffle=True, random_state=55)\n",
    "    outcomes=[]\n",
    "    sub=np.zeros((test.shape[0], 3))  \n",
    "    for n_fold, (train_index, val_index) in enumerate(folds.split(train_x, train_y)):\n",
    "        X_train, X_val = train_x.iloc[train_index], train_x.iloc[val_index]\n",
    "        y_train, y_val = train_y.iloc[train_index], train_y.iloc[val_index]\n",
    "        \n",
    "#         dtrain = xgb.DMatrix(X_train, y_train)\n",
    "#         dtest = xgb.DMatrix(X_val)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        predictions=clf.predict_proba(X_val)\n",
    "        \n",
    "        #final_gb = xgb.train(params, dtrain, num_boost_round=200, verbose_eval=50)\n",
    "\n",
    "        #predictions = final_gb.predict(dtest)\n",
    "        \n",
    "        logloss=log_loss(to_categorical(y_val['credit']), predictions)\n",
    "        outcomes.append(logloss)\n",
    "        print(f\"FOLD {n_fold} : logloss:{logloss}\")\n",
    "        \n",
    "        sub+=clf.predict_proba(test)\n",
    "        \n",
    "        \n",
    "    mean_outcome=np.mean(outcomes)\n",
    "    \n",
    "    print(\"Mean:{}\".format(mean_outcome))\n",
    "    return sub/folds.n_splits\n",
    "\n",
    "my_submission = run_kfold(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "liable-automation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04819474, 0.09246179, 0.85934347],\n",
       "       [0.2432932 , 0.23357293, 0.52313386],\n",
       "       [0.05332712, 0.08692874, 0.85974413],\n",
       "       ...,\n",
       "       [0.02024993, 0.07179929, 0.90795078],\n",
       "       [0.13012759, 0.24752395, 0.62234845],\n",
       "       [0.06288433, 0.21253935, 0.72457634]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "occupational-tulsa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26457</td>\n",
       "      <td>0.048195</td>\n",
       "      <td>0.092462</td>\n",
       "      <td>0.859343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26458</td>\n",
       "      <td>0.243293</td>\n",
       "      <td>0.233573</td>\n",
       "      <td>0.523134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26459</td>\n",
       "      <td>0.053327</td>\n",
       "      <td>0.086929</td>\n",
       "      <td>0.859744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26460</td>\n",
       "      <td>0.109893</td>\n",
       "      <td>0.117643</td>\n",
       "      <td>0.772465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26461</td>\n",
       "      <td>0.066512</td>\n",
       "      <td>0.127067</td>\n",
       "      <td>0.806421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>36452</td>\n",
       "      <td>0.115962</td>\n",
       "      <td>0.301663</td>\n",
       "      <td>0.582375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>36453</td>\n",
       "      <td>0.224034</td>\n",
       "      <td>0.301054</td>\n",
       "      <td>0.474912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>36454</td>\n",
       "      <td>0.020250</td>\n",
       "      <td>0.071799</td>\n",
       "      <td>0.907951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>36455</td>\n",
       "      <td>0.130128</td>\n",
       "      <td>0.247524</td>\n",
       "      <td>0.622348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36456</td>\n",
       "      <td>0.062884</td>\n",
       "      <td>0.212539</td>\n",
       "      <td>0.724576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         0         1         2\n",
       "0     26457  0.048195  0.092462  0.859343\n",
       "1     26458  0.243293  0.233573  0.523134\n",
       "2     26459  0.053327  0.086929  0.859744\n",
       "3     26460  0.109893  0.117643  0.772465\n",
       "4     26461  0.066512  0.127067  0.806421\n",
       "...     ...       ...       ...       ...\n",
       "9995  36452  0.115962  0.301663  0.582375\n",
       "9996  36453  0.224034  0.301054  0.474912\n",
       "9997  36454  0.020250  0.071799  0.907951\n",
       "9998  36455  0.130128  0.247524  0.622348\n",
       "9999  36456  0.062884  0.212539  0.724576\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.read_csv('./open/sample_submission.csv')\n",
    "submission.loc[:,1:]=my_submission\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "killing-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submit/10fold_xgb_0.6958.csv', index=False) # 0.7272812144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "persistent-pharmaceutical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26457</td>\n",
       "      <td>0.048195</td>\n",
       "      <td>0.092462</td>\n",
       "      <td>0.859343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26458</td>\n",
       "      <td>0.243293</td>\n",
       "      <td>0.233573</td>\n",
       "      <td>0.523134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26459</td>\n",
       "      <td>0.053327</td>\n",
       "      <td>0.086929</td>\n",
       "      <td>0.859744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26460</td>\n",
       "      <td>0.109893</td>\n",
       "      <td>0.117643</td>\n",
       "      <td>0.772465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26461</td>\n",
       "      <td>0.066512</td>\n",
       "      <td>0.127067</td>\n",
       "      <td>0.806421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26462</td>\n",
       "      <td>0.045072</td>\n",
       "      <td>0.082720</td>\n",
       "      <td>0.872208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26463</td>\n",
       "      <td>0.620859</td>\n",
       "      <td>0.355267</td>\n",
       "      <td>0.023874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26464</td>\n",
       "      <td>0.086823</td>\n",
       "      <td>0.109106</td>\n",
       "      <td>0.804070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26465</td>\n",
       "      <td>0.051528</td>\n",
       "      <td>0.163646</td>\n",
       "      <td>0.784826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26466</td>\n",
       "      <td>0.058361</td>\n",
       "      <td>0.329386</td>\n",
       "      <td>0.612253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26467</td>\n",
       "      <td>0.110747</td>\n",
       "      <td>0.192935</td>\n",
       "      <td>0.696318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26468</td>\n",
       "      <td>0.058593</td>\n",
       "      <td>0.101472</td>\n",
       "      <td>0.839935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26469</td>\n",
       "      <td>0.529046</td>\n",
       "      <td>0.126387</td>\n",
       "      <td>0.344567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26470</td>\n",
       "      <td>0.093818</td>\n",
       "      <td>0.183346</td>\n",
       "      <td>0.722837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26471</td>\n",
       "      <td>0.061760</td>\n",
       "      <td>0.243687</td>\n",
       "      <td>0.694552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26472</td>\n",
       "      <td>0.141815</td>\n",
       "      <td>0.293662</td>\n",
       "      <td>0.564524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26473</td>\n",
       "      <td>0.057776</td>\n",
       "      <td>0.231359</td>\n",
       "      <td>0.710865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26474</td>\n",
       "      <td>0.453189</td>\n",
       "      <td>0.525329</td>\n",
       "      <td>0.021482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26475</td>\n",
       "      <td>0.323200</td>\n",
       "      <td>0.249539</td>\n",
       "      <td>0.427261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26476</td>\n",
       "      <td>0.037035</td>\n",
       "      <td>0.097949</td>\n",
       "      <td>0.865016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index         0         1         2\n",
       "0   26457  0.048195  0.092462  0.859343\n",
       "1   26458  0.243293  0.233573  0.523134\n",
       "2   26459  0.053327  0.086929  0.859744\n",
       "3   26460  0.109893  0.117643  0.772465\n",
       "4   26461  0.066512  0.127067  0.806421\n",
       "5   26462  0.045072  0.082720  0.872208\n",
       "6   26463  0.620859  0.355267  0.023874\n",
       "7   26464  0.086823  0.109106  0.804070\n",
       "8   26465  0.051528  0.163646  0.784826\n",
       "9   26466  0.058361  0.329386  0.612253\n",
       "10  26467  0.110747  0.192935  0.696318\n",
       "11  26468  0.058593  0.101472  0.839935\n",
       "12  26469  0.529046  0.126387  0.344567\n",
       "13  26470  0.093818  0.183346  0.722837\n",
       "14  26471  0.061760  0.243687  0.694552\n",
       "15  26472  0.141815  0.293662  0.564524\n",
       "16  26473  0.057776  0.231359  0.710865\n",
       "17  26474  0.453189  0.525329  0.021482\n",
       "18  26475  0.323200  0.249539  0.427261\n",
       "19  26476  0.037035  0.097949  0.865016"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "julian-retirement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>31375</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.072123</td>\n",
       "      <td>0.869677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       0         1         2\n",
       "4918  31375  0.0582  0.072123  0.869677"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.read_csv('./submit/10fold_xgb_0.6974.csv') # 0.7272812144\n",
    "submission[submission['index']==31375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-civilian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
