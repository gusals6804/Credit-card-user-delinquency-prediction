{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "finnish-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-overhead",
   "metadata": {},
   "source": [
    "## Data Load & Preprocessing\n",
    "+ 훈련에 필요없는 index 컬럼 삭제.\n",
    "+ missing value를 모두 NAN 문자열로 대체\n",
    "+ dtype object 인 컬럼들을 onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dedicated-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./open/train.csv')\n",
    "train = train.drop(['index'], axis=1)\n",
    "train.fillna('NAN', inplace=True) \n",
    "\n",
    "\n",
    "test = pd.read_csv('./open/test.csv')\n",
    "test = test.drop(['index'], axis=1)\n",
    "test.fillna('NAN', inplace=True)\n",
    "\n",
    "submit = pd.read_csv('./open/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "precise-august",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36457, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.concat([train, test], axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "light-carbon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0     19463\n",
       "1.0      6987\n",
       "3.0      6421\n",
       "4.0      3106\n",
       "5.0       397\n",
       "6.0        58\n",
       "7.0        19\n",
       "15.0        3\n",
       "9.0         2\n",
       "20.0        1\n",
       "Name: family_size, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['family_size'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-terrace",
   "metadata": {},
   "source": [
    "'phone',  'email', 'work_phone' 3가지 컬럼도 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "activated-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=train.drop('occyp_type', axis=1)\n",
    "# test=test.drop('occyp_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "matched-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train=train.drop(['email'], axis=1)\n",
    "# test=test.drop(['email'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thermal-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_col = []\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == 'object':\n",
    "        object_col.append(col)\n",
    "#     elif col in ['phone',  'email', 'work_phone', 'FLAG_MOBIL']:\n",
    "#         object_col.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sunrise-individual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'car',\n",
       " 'reality',\n",
       " 'income_type',\n",
       " 'edu_type',\n",
       " 'family_type',\n",
       " 'house_type',\n",
       " 'occyp_type']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ready-tourist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(train.loc[:,object_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "horizontal-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "train.drop(object_col, axis=1, inplace=True)\n",
    "train = pd.concat([train, train_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "underlying-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_onehot_df = pd.DataFrame(enc.transform(test.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "test.drop(object_col, axis=1, inplace=True)\n",
    "test = pd.concat([test, test_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-strip",
   "metadata": {},
   "source": [
    "## 수치형 데이터 feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "modern-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['income_total'] = train['income_total'].astype(object)\n",
    "train['income_total'] = train['income_total']/10000 \n",
    "#train['Month_BIRTH'] = train['DAYS_BIRTH']/30 \n",
    "#train['Month_EMPLOYED'] = train['DAYS_EMPLOYED']/30 \n",
    "#train['q_BIRTH'] = train['DAYS_BIRTH']/90\n",
    "#train['q_EMPLOYED'] = train['DAYS_EMPLOYED']/90\n",
    "train['year_BIRTH'] = train['DAYS_BIRTH']/365\n",
    "train['year_EMPLOYED'] = train['DAYS_EMPLOYED']/365\n",
    "train['begin_year'] = train['begin_month']/12\n",
    "train.loc[train['DAYS_EMPLOYED'] < 0,'DAYS_EMPLOYED']=0\n",
    "train.loc[train['DAYS_EMPLOYED'] > 0,'DAYS_EMPLOYED']=1\n",
    "train.loc[train['begin_month'] < 0,'begin_month']=0\n",
    "train.loc[train['begin_month'] > 0,'begin_month']=1\n",
    "train.loc[train['child_num'] >= 3,'child_num']=3\n",
    "train.loc[train['family_size'] >= 5,'child_num']=5\n",
    "#train['income_total3'] = train['income_total']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "further-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emp = []\n",
    "for i in range(len(train['DAYS_EMPLOYED'])):\n",
    "    if train['year_EMPLOYED'][i] > 0:\n",
    "        train_emp.append(0)\n",
    "    else:\n",
    "        train_emp.append(train['year_EMPLOYED'][i])\n",
    "train['yes_emp'] = train_emp     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "continuing-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['income_total'] = test['income_total'].astype(object)\n",
    "test['income_total'] = test['income_total']/10000 \n",
    "#test['Month_BIRTH'] = test['DAYS_BIRTH']/30 \n",
    "#test['Month_EMPLOYED'] = test['DAYS_EMPLOYED']/30\n",
    "#test['q_BIRTH'] = test['DAYS_BIRTH']/90\n",
    "#test['q_EMPLOYED'] = test['DAYS_EMPLOYED']/90\n",
    "test['year_BIRTH'] = test['DAYS_BIRTH']/365\n",
    "test['year_EMPLOYED'] = test['DAYS_EMPLOYED']/365\n",
    "test['begin_year'] = test['begin_month']/12\n",
    "test.loc[test['DAYS_EMPLOYED'] < 0,'DAYS_EMPLOYED']=0\n",
    "test.loc[test['DAYS_EMPLOYED'] > 0,'DAYS_EMPLOYED']=1\n",
    "test.loc[test['begin_month'] < 0,'begin_month']=0\n",
    "test.loc[test['begin_month'] > 0,'begin_month']=1\n",
    "test.loc[test['child_num'] >= 3,'child_num']=3\n",
    "test.loc[test['family_size'] >= 5,'child_num']=5\n",
    "#test['income_total3'] = test['income_total']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "recovered-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_emp = []\n",
    "for i in range(len(test['DAYS_EMPLOYED'])):\n",
    "    if test['year_EMPLOYED'][i] > 0:\n",
    "        test_emp.append(0)\n",
    "    else:\n",
    "        test_emp.append(test['year_EMPLOYED'][i])\n",
    "test['yes_emp'] = test_emp  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "opposite-continent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.544, 28.5]     23146\n",
      "(28.5, 54.3]       3037\n",
      "(54.3, 80.1]        216\n",
      "(80.1, 105.9]        47\n",
      "(105.9, 131.7]        2\n",
      "(131.7, 157.5]        9\n",
      "Name: income_total, dtype: int64\n",
      "(-68.958, -64.13]     848\n",
      "(-64.13, -59.35]     2340\n",
      "(-59.35, -54.57]     2665\n",
      "(-54.57, -49.79]     2773\n",
      "(-49.79, -45.01]     2941\n",
      "(-45.01, -40.23]     3497\n",
      "(-40.23, -35.45]     3748\n",
      "(-35.45, -30.67]     3498\n",
      "(-30.67, -25.89]     3271\n",
      "(-25.89, -21.11]      876\n",
      "Name: year_BIRTH, dtype: int64\n",
      "(-60.061, -50.0]    4099\n",
      "(-50.0, -40.0]      4925\n",
      "(-40.0, -30.0]      5865\n",
      "(-30.0, -20.0]      6686\n",
      "(-20.0, -10.0]      7689\n",
      "(-10.0, 0.0]        7193\n",
      "Name: begin_month, dtype: int64\n",
      "(-44.094, 61.322]      22019\n",
      "(61.322, 165.694]          0\n",
      "(165.694, 270.065]         0\n",
      "(270.065, 374.437]         0\n",
      "(374.437, 478.808]         0\n",
      "(478.808, 583.18]          0\n",
      "(583.18, 687.551]          0\n",
      "(687.551, 791.923]         0\n",
      "(791.923, 896.294]         0\n",
      "(896.294, 1000.666]     4438\n",
      "Name: year_EMPLOYED, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['income_total'].value_counts(bins=6,sort=False))\n",
    "print(train['year_BIRTH'].value_counts(bins=10,sort=False))\n",
    "print(data['begin_month'].value_counts(bins=6,sort=False))\n",
    "print(train['year_EMPLOYED'].value_counts(bins=10,sort=False))\n",
    "#data['DAYS_EMPLOYED'].plot(kind='hist',bins=2,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "orange-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minus 변경하고\n",
    "#구간화 함수\n",
    "def make_bin(df, variable, n):\n",
    "    data = df\n",
    "    data[variable] =- data[variable]\n",
    "    count, bin_dividers = np.histogram(data[variable], bins=n)\n",
    "    bin_names=[str(i) for i in range(n)]\n",
    "    data['%s_bin' % variable]=pd.cut(x=data[variable], bins=bin_dividers, labels=bin_names, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stretch-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_bin(train, 'income_total', n=7)\n",
    "make_bin(train, 'year_BIRTH', n=10)\n",
    "make_bin(train, 'begin_month', n=6)\n",
    "make_bin(train, 'yes_emp', n=10)\n",
    "#make_bin(train, 'DAYS_EMPLOYED', n=2)\n",
    "#make_bin(train, 'child_num', n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abstract-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_bin(test, 'income_total', n=7)\n",
    "make_bin(test, 'year_BIRTH', n=10)\n",
    "make_bin(test, 'begin_month', n=6)\n",
    "make_bin(test, 'yes_emp', n=10)\n",
    "#make_bin(test, 'DAYS_EMPLOYED', n=2)\n",
    "#make_bin(test, 'child_num', n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "underlying-intranet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder()\n",
    "object_col = ['income_total_bin', 'year_BIRTH_bin', 'begin_month_bin', 'yes_emp_bin']\n",
    "enc.fit(train.loc[:,object_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "improving-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "train.drop(object_col, axis=1, inplace=True)\n",
    "train = pd.concat([train, train_onehot_df], axis=1)\n",
    "#train = train.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED', 'begin_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aggregate-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_onehot_df = pd.DataFrame(enc.transform(test.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "test.drop(object_col, axis=1, inplace=True)\n",
    "test = pd.concat([test, test_onehot_df], axis=1)\n",
    "#test = test.drop(['DAYS_BIRTH', 'DAYS_EMPLOYED', 'begin_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "linear-enemy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26457, 89), (10000, 88))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "nuclear-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds=[]\n",
    "for train_idx, valid_idx in skf.split(train, train['credit']):\n",
    "    folds.append((train_idx, valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "tender-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================1============================================\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 0.648953\tvalid_1's multi_logloss: 0.750248\n",
      "[200]\ttraining's multi_logloss: 0.562382\tvalid_1's multi_logloss: 0.733084\n",
      "[300]\ttraining's multi_logloss: 0.500723\tvalid_1's multi_logloss: 0.727882\n",
      "[400]\ttraining's multi_logloss: 0.447799\tvalid_1's multi_logloss: 0.726733\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttraining's multi_logloss: 0.471481\tvalid_1's multi_logloss: 0.726043\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================2============================================\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 0.64557\tvalid_1's multi_logloss: 0.762176\n",
      "[200]\ttraining's multi_logloss: 0.556183\tvalid_1's multi_logloss: 0.748587\n",
      "[300]\ttraining's multi_logloss: 0.492039\tvalid_1's multi_logloss: 0.744265\n",
      "[400]\ttraining's multi_logloss: 0.441873\tvalid_1's multi_logloss: 0.745668\n",
      "Early stopping, best iteration is:\n",
      "[350]\ttraining's multi_logloss: 0.465535\tvalid_1's multi_logloss: 0.742643\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================3============================================\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 0.650064\tvalid_1's multi_logloss: 0.757589\n",
      "[200]\ttraining's multi_logloss: 0.55822\tvalid_1's multi_logloss: 0.742276\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's multi_logloss: 0.528992\tvalid_1's multi_logloss: 0.741658\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================4============================================\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 0.644156\tvalid_1's multi_logloss: 0.753312\n",
      "[200]\ttraining's multi_logloss: 0.557028\tvalid_1's multi_logloss: 0.735798\n",
      "[300]\ttraining's multi_logloss: 0.491476\tvalid_1's multi_logloss: 0.729848\n",
      "Early stopping, best iteration is:\n",
      "[301]\ttraining's multi_logloss: 0.49083\tvalid_1's multi_logloss: 0.729745\n",
      "================================================================================\n",
      "\n",
      "\n",
      "====================================5============================================\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 0.648954\tvalid_1's multi_logloss: 0.754178\n",
      "[200]\ttraining's multi_logloss: 0.561869\tvalid_1's multi_logloss: 0.74127\n",
      "[300]\ttraining's multi_logloss: 0.498257\tvalid_1's multi_logloss: 0.734968\n",
      "Early stopping, best iteration is:\n",
      "[298]\ttraining's multi_logloss: 0.499483\tvalid_1's multi_logloss: 0.734578\n",
      "================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "lgb_models={}\n",
    "for fold in range(5):\n",
    "    print(f'===================================={fold+1}============================================')\n",
    "    train_idx, valid_idx = folds[fold]\n",
    "    X_train, X_valid, y_train, y_valid = train.drop(['credit'],axis=1).iloc[train_idx].values, train.drop(['credit'],axis=1).iloc[valid_idx].values,\\\n",
    "                                         train['credit'][train_idx].values, train['credit'][valid_idx].values \n",
    "    lgb = LGBMClassifier(n_estimators=1000)\n",
    "    lgb.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
    "            early_stopping_rounds=50,\n",
    "           verbose=100)\n",
    "    lgb_models[fold]=lgb\n",
    "    print(f'================================================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deluxe-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.iloc[:,1:]=0\n",
    "for fold in range(5):\n",
    "    submit.iloc[:,1:] += lgb_models[fold].predict_proba(test)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "worthy-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('./submit/5fold_lgb3.csv', index=False) # 0.7272812144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "changing-laser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26457</td>\n",
       "      <td>0.047761</td>\n",
       "      <td>0.098220</td>\n",
       "      <td>0.854018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26458</td>\n",
       "      <td>0.214729</td>\n",
       "      <td>0.155689</td>\n",
       "      <td>0.629582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26459</td>\n",
       "      <td>0.046273</td>\n",
       "      <td>0.103584</td>\n",
       "      <td>0.850143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26460</td>\n",
       "      <td>0.106974</td>\n",
       "      <td>0.118443</td>\n",
       "      <td>0.774583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26461</td>\n",
       "      <td>0.079316</td>\n",
       "      <td>0.164080</td>\n",
       "      <td>0.756604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26462</td>\n",
       "      <td>0.083584</td>\n",
       "      <td>0.148262</td>\n",
       "      <td>0.768154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26463</td>\n",
       "      <td>0.456232</td>\n",
       "      <td>0.543424</td>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26464</td>\n",
       "      <td>0.096812</td>\n",
       "      <td>0.141025</td>\n",
       "      <td>0.762164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26465</td>\n",
       "      <td>0.102001</td>\n",
       "      <td>0.148786</td>\n",
       "      <td>0.749213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26466</td>\n",
       "      <td>0.064506</td>\n",
       "      <td>0.263556</td>\n",
       "      <td>0.671939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26467</td>\n",
       "      <td>0.091895</td>\n",
       "      <td>0.164906</td>\n",
       "      <td>0.743199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26468</td>\n",
       "      <td>0.073646</td>\n",
       "      <td>0.130520</td>\n",
       "      <td>0.795834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26469</td>\n",
       "      <td>0.321000</td>\n",
       "      <td>0.155543</td>\n",
       "      <td>0.523457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26470</td>\n",
       "      <td>0.063178</td>\n",
       "      <td>0.147497</td>\n",
       "      <td>0.789325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26471</td>\n",
       "      <td>0.115169</td>\n",
       "      <td>0.218488</td>\n",
       "      <td>0.666343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26472</td>\n",
       "      <td>0.114039</td>\n",
       "      <td>0.186309</td>\n",
       "      <td>0.699652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>26473</td>\n",
       "      <td>0.060818</td>\n",
       "      <td>0.145168</td>\n",
       "      <td>0.794014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26474</td>\n",
       "      <td>0.352708</td>\n",
       "      <td>0.647108</td>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26475</td>\n",
       "      <td>0.107734</td>\n",
       "      <td>0.324218</td>\n",
       "      <td>0.568048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26476</td>\n",
       "      <td>0.034429</td>\n",
       "      <td>0.105257</td>\n",
       "      <td>0.860314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index         0         1         2\n",
       "0   26457  0.047761  0.098220  0.854018\n",
       "1   26458  0.214729  0.155689  0.629582\n",
       "2   26459  0.046273  0.103584  0.850143\n",
       "3   26460  0.106974  0.118443  0.774583\n",
       "4   26461  0.079316  0.164080  0.756604\n",
       "5   26462  0.083584  0.148262  0.768154\n",
       "6   26463  0.456232  0.543424  0.000344\n",
       "7   26464  0.096812  0.141025  0.762164\n",
       "8   26465  0.102001  0.148786  0.749213\n",
       "9   26466  0.064506  0.263556  0.671939\n",
       "10  26467  0.091895  0.164906  0.743199\n",
       "11  26468  0.073646  0.130520  0.795834\n",
       "12  26469  0.321000  0.155543  0.523457\n",
       "13  26470  0.063178  0.147497  0.789325\n",
       "14  26471  0.115169  0.218488  0.666343\n",
       "15  26472  0.114039  0.186309  0.699652\n",
       "16  26473  0.060818  0.145168  0.794014\n",
       "17  26474  0.352708  0.647108  0.000184\n",
       "18  26475  0.107734  0.324218  0.568048\n",
       "19  26476  0.034429  0.105257  0.860314"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-orange",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
